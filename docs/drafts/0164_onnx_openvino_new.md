---
title: "Run ONNX model with OpenVINO™ in Intel® powered hardware"
permalink: /docs/onnx_openvino_old/
excerpt: "Run ONNX model with OpenVINO™ in Intel® powered hardware"
variable:
  - platform: windows
    name: Windows
  - platform: macos
    name: macOS
last_modified_at: 2019-09-24
---

## Run ONNX models with OpenVINO™ in Intel® powered hardware

| **Intel® powered developer kits for ONNX and Azure IoT** |  |
| :----------- |
| **[UP Squared* AI Vision X Developer Kit](https://software.intel.com/en-us/iot/hardware/up-squared-ai-vision-dev-kit){:target="_blank"}** that comes pre-loaded with Intel® Distribution of OpenVINO to optimize and accelerate workloads utilizing Intel® CPU and GPU or offload the workloads to the optional AI Core X Mini PCIe* card with the Intel® Movidius™ Myriad™ X Vision Processing Unit (VPU). All bundled into one solution powered by Intel industrial grade sensors for commercial deployments.  | ![UP2]({{ '/assets/images/devices_up2.png' | relative_url }})|

| Solution example |
| :----------- |
|  Intel and Microsoft joined forces to create development tools that make it easier for you to use the cloud, the edge or both, depending on your need. The latest is an execution provider (EP) plugin that integrates two valuable tools: the Intel Distribution of [OpenVINO™ toolkit](https://software.intel.com/en-us/openvino-toolkit){:target="_blank"} and [Open Neural Network Exchange](https://onnx.ai/){:target="_blank"} (ONNX) Runtime. The goal is to give you the ability to write once and deploy everywhere — in the cloud or at the edge. 
Read [Intel's blog](https://blogs.intel.com/iot/2019/08/21/intel-and-microsoft-advance-edge-to-cloud-inference-for-ai/#gs.5vaef1){:target="_blank"} regarding advancing edge to cloud inferencing for AI. |

| This solution example provides step by step instructions for enabling [ONNX](https://onnx.ai/){:target="_blank"} with on Intel powered devices. ONNX is an open format to represent deep learning models. With ONNX, AI developers can more easily move models between state-of-the-art tools and choose the combination that is best for them. ONNX is developed and supported by a community of partners. |
| [ONNX Runtime with OpenVINO™ by Microsoft](https://github.com/Azure-Samples/onnxruntime-iot-edge/blob/master/README-ONNXRUNTIME-OpenVINO.md){:target="_blank"} | 
| [ONNX Runtime with OpenVINO™ by Intel](https://github.com/intel/Edge-Analytics-FaaS/tree/R1_2019/Azure-IoT-Edge/OnnxRuntime){:target="_blank"} |

| Exmaple solution diagram |
| ![Enable ONNX with UP Squared* AI Vision X Developer Kit]({{ '/assets/images/devices_onnx_up2.png' | relative_url }}) |

