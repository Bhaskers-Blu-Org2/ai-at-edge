---
title: "Run ONNX model with Jetson Nano"
permalink: /docs/jetsonnano/
excerpt: "Run ONNX model with Jetson Nano"
variable:
  - platform: windows
    name: Windows
  - platform: macos
    name: macOS
last_modified_at: 2019-09-02
---
<!-- <html><font size="5"> -->
## Run ONNX models with NVIDIA® Jetson Nano™

<html><table><tr bgcolor="#68adc4"><td colspan="2"><b>
<a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/" target="_blank">NVIDIA® Jetson Nano™</a></b>
<tr><td>
NVIDIA® Jetson Nano™ Developer Kit is a small, powerful computer that lets you run multiple neural networks in parallel for applications like image classification, object detection, segmentation, and speech processing. All in an easy-to-use platform that runs in as little as 5 watts. It opens new worlds of embedded IoT applications, including entry-level Network Video Recorders (NVRs), home robots, and intelligent gateways with full analytics capabilities. 
</td>
<td width="30%">
<img src="{{'assets/images/devices_jetson_nano.jpg' | relative_url}}">
<!-- ![Jetson Nano]({{ '/assets/images/devices_jetson_nano.jpg' | relative_url }})  -->
</td></tr>
<tr bgcolor="#68adc4"><td colspan="2"><b>
Solution example
</b></td></tr>
<tr><td colspan="2">
This solution example provides step by step instructions for enabling <a href="https://onnx.ai/" target="_blank">ONNX</a> on Jetson Nano. ONNX is an open format to represent deep learning models. With ONNX, AI developers can more easily move models between state-of-the-art tools and choose the combination that is best for them. ONNX is developed and supported by a community of partners. Use this example to enable running ONNX models with Jetson Nano.<br><a href="https://github.com/Azure-Samples/onnxruntime-iot-edge/blob/master/README-ONNXRUNTIME-arm64.md" target="_blank">ONNX Runtime IoT Edge GitHub</a>
</td></tr>
<tr><td>
Solution flow example
<img src="{{'/assets/images/devices_onnx_jetson.jpg' | relative_url}}" alt="Solution architecture picture" width="100%">
</td></tr>

